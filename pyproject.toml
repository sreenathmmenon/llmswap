[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llmswap"
version = "5.1.7"
description = "cURL for LLMs - Universal SDK + CLI with multiple second brains. Works with Claude Sonnet 4.5, GPT-4 o1, Gemini, Cohere, xAI Grok, Sarvam AI, Perplexity, watsonx, Groq, Ollama. Features: workspace memory, auto-learning journals, teaching-first AI (Eklavya), persona rotation, decision logs, 50-90% cost savings, zero lock-in. Python SDK or CLI. Alternative to Claude Code, Cursor, Continue.dev, Copilot."
readme = "README.md"
requires-python = ">=3.8"
license = {file = "LICENSE"}
authors = [
    {name = "Sreenath M Menon", email = "sreenathmmmenon@gmail.com"},
]
keywords = [
    "llm",
    "ai", 
    "openai",
    "anthropic",
    "claude",
    "gemini",
    "watsonx",
    "ibm-watsonx",
    "ibm-watson",
    "watson-ai",
    "ollama",
    "groq",
    "groq-inference",
    "fast-inference",
    "github-copilot-alternative",
    "copilot-cli",
    "copilot-cli-alternative",
    "open-source-copilot",
    "copilot-alternative",
    "copilot-replacement",
    "code-generation",
    "natural-language-to-code",
    "command-generation",
    "ai-code-generation",
    "text-to-code",
    "bash-generator",
    "python-generator",
    "ai-code-assistant",
    "developer-ai-tools",
    "self-hosted-ai",
    "code-completion-api",
    "ai-pair-programming",
    "multi-llm-copilot",
    "gpt-4",
    "granite",
    "llama",
    "mistral",
    "llm-api",
    "langchain-alternative",
    "litellm-alternative",
    "multi-llm",
    "llm-switching",
    "provider-fallback",
    "cli",
    "ai-cli",
    "terminal-ai",
    "terminal-assistant",
    "command-line-ai",
    "shell-integration",
    "vim-integration",
    "vim-plugin",
    "editor-integration",
    "ai-chat",
    "ai-assistant",
    "cost-optimization",
    "response-caching",
    "code-review",
    "ai-code-review",
    "debugging",
    "ai-debugging",
    "log-analysis",
    "ai-logs",
    "token-tracking",
    "usage-analytics",
    "cost-analytics",
    "developer-tools",
    "hackathon",
    "hackathon-starter",
    "rag",
    "retrieval-augmented-generation",
    "vector-database",
    "embeddings",
    "chatgpt-alternative",
    "claude-code-alternative",
    "ai-mentor",
    "ai-teaching",
    "personalized-ai",
    "ai-persona",
    "eklavya",
    "ai-learning",
    "coding-mentor",
    "ai-tutor",
    "gemini-cli-alternative", 
    "openai-cli-alternative",
    "multi-provider-cli",
    "universal-ai-cli",
    "ai-provider-switcher",
    "provider-agnostic-cli",
    "llm-cli-interface",
    "ai-chat-cli",
    "terminal-ai-chat",
    "cli-ai-assistant",
    "multi-llm-cli",
    "cross-provider-cli",
    "perplexity",
    "cohere",
    "streamlit",
    "fastapi",
    "langchain",
    "pinecone",
    "chromadb",
    "llm-gateway",
    "enterprise-ai",
    "conversational-ai",
    "ai-teaching",
    "age-appropriate-ai",
    "personalized-ai",
    "ai-mentor",
    "multi-provider-chat",
    "provider-switching",
    "educational-ai",
    "ai-tutor",
    "teaching-assistant",
    "adaptive-learning",
    "conversational-cli",
    "multi-modal-ai",
    "ai-personas",
    "custom-ai-personas",
    "contextual-ai",
    "session-management",
    "ai-context-switching",
    "python-sdk",
    "sdk",
    "api-client",
    "llm-sdk",
    "ai-sdk",
    "multi-provider-sdk",
    "provider-agnostic-sdk",
    "universal-ai-sdk",
    "openai-alternative-sdk",
    "anthropic-sdk-alternative",
    "gemini-sdk-alternative",
    "no-vendor-lock-in",
    "vendor-agnostic",
    "provider-switching",
    "dynamic-provider-switching",
    "llm-abstraction",
    "ai-abstraction-layer",
    "sdk-and-cli",
    "python-sdk-cli",
    "library-and-cli",
    "workspace-system",
    "project-memory",
    "learning-journal",
    "context-aware-ai",
    "persistent-context",
    "architecture-decisions",
    "claude-sonnet-4-5",
    "claude-4-5",
    "cursor-alternative",
    "continue-dev-alternative",
    "second-brain",
    "multiple-contexts",
    "persona-rotation",
    "ai-straying-prevention",
    "project-knowledge-base",
    "lmarena",
    "lmarena-tested-models",
    "arena-validated-models",
    "battle-tested-ai",
    "production-validated-llm",
    "top-rated-models",
    "leaderboard-models",
    "grok-4",
    "grok-4-0709",
    "grok-4-fast",
    "xai-grok",
    "sonnet-4-5",
    "sonnet-4.5",
    "sarvam-ai",
    "indian-language-ai",
    "multilingual-ai",
    "10-providers",
    "ai-memory",
    "workspace-ai",
    "project-context",
    "web-ui",
    "model-comparison",
    "llm-comparison",
    "side-by-side-comparison",
    "ai-comparison-tool",
    "model-evaluation",
    "llm-benchmarking",
    "visual-comparison",
    "cost-comparison",
    "speed-comparison",
    "quality-comparison",
    "multi-model-testing",
    "prompt-testing",
    "response-comparison",
    "ai-testing-tool",
    "model-testing",
    "llm-evaluation",
    "browser-ui",
    "web-interface",
    "flask-ui",
    "comparison-dashboard",
    "ai-dashboard"
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology", 
    "Intended Audience :: Science/Research",
    "Intended Audience :: Education",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
    "Topic :: Communications :: Chat",
    "Topic :: Text Processing :: Linguistic",
    "Topic :: System :: Distributed Computing",
    "Framework :: AsyncIO",
    "Operating System :: OS Independent",
    "Environment :: Console",
    "Typing :: Typed",
]
dependencies = [
    "anthropic>=0.3.0",
    "openai>=1.0.0",
    "google-generativeai>=0.3.0",
    "requests>=2.25.0",
    "python-dotenv>=0.19.0",
    "httpx>=0.24.0",
    "aiohttp>=3.8.0",
    "aiofiles>=23.0.0",
    "groq>=0.4.0",
    "cohere>=5.16.0",
]

[project.optional-dependencies]
watsonx = ["ibm-watsonx-ai>=0.0.5"]
web = [
    "flask>=3.0.0",
    "flask-cors>=4.0.0",
]
all = [
    "anthropic>=0.3.0",
    "openai>=1.0.0",
    "google-generativeai>=0.3.0",
    "ibm-watsonx-ai>=0.0.5",
    "groq>=0.4.0",
    "cohere>=5.16.0",
    "flask>=3.0.0",
    "flask-cors>=4.0.0",
]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=22.0.0",
    "isort>=5.10.0",
    "mypy>=0.991",
]

[project.scripts]
llmswap = "llmswap.cli:main"

[project.urls]
Homepage = "https://github.com/sreenathmmenon/llmswap"
Documentation = "https://github.com/sreenathmmenon/llmswap#readme"
Repository = "https://github.com/sreenathmmenon/llmswap"
Issues = "https://github.com/sreenathmmenon/llmswap/issues"
Changelog = "https://github.com/sreenathmmenon/llmswap/blob/main/CHANGELOG.md"

[tool.hatch.build.targets.wheel]
packages = ["llmswap"]

[tool.black]
line-length = 88
target-version = ['py38']

[tool.isort]
profile = "black"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]